{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#zeroLr = git clone https://github.com/kohya-ss/sd-scripts --branch sd3\n",
        "from IPython.utils import capture\n",
        "with capture.capture_output() as cap:\n",
        "  #\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  #\n",
        "  %cd /content\n",
        "  !mkdir /content/drive/MyDrive/dataset\n",
        "  !mkdir /content/drive/MyDrive/train\n",
        "  !mkdir /content/log\n",
        "  !mkdir -p /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  !curl -Lo /content/zeroLR.zip https://huggingface.co/josemerinom/flux/resolve/main/zeroLR_sd3_jun01.zip\n",
        "  !curl -Lo /content/default_config.yaml https://huggingface.co/josemerinom/flux/resolve/main/default_config.yaml\n",
        "  #\n",
        "  !curl -Lo /content/ae.safetensors https://huggingface.co/josemerinom/flux/resolve/main/ae.safetensors\n",
        "  !curl -Lo /content/clip_l.safetensors https://huggingface.co/josemerinom/flux/resolve/main/clip_l.safetensors\n",
        "  !curl -Lo /content/t5xxl_fp8_e4m3fn.safetensors https://huggingface.co/josemerinom/flux/resolve/main/t5xxl_fp8_e4m3fn.safetensors\n",
        "  !curl -Lo /content/flux1-dev-fp8.safetensors https://huggingface.co/josemerinom/flux/resolve/main/flux1-dev-fp8.safetensors\n",
        "  #\n",
        "  !unzip -u /content/zeroLR.zip\n",
        "  !cp -r /content/default_config.yaml /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  !pip uninstall -y peft gradio accelerate torch torchvision torchaudio\n",
        "  #\n",
        "  !pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "  #\n",
        "  !pip install accelerate==0.33.0\n",
        "  !pip install transformers==4.44.0\n",
        "  !pip install diffusers[torch]==0.25.0\n",
        "  !pip install ftfy==6.1.1\n",
        "  !pip install albumentations==1.3.0\n",
        "  !pip install opencv-python==4.8.1.78\n",
        "  !pip install einops==0.7.0\n",
        "  !pip install pytorch-lightning==1.9.0\n",
        "  !pip install bitsandbytes==0.44.0\n",
        "  !pip install lion-pytorch==0.0.6\n",
        "  !pip install schedulefree==1.4\n",
        "  !pip install pytorch-optimizer==3.5.0\n",
        "  !pip install prodigy-plus-schedule-free==1.9.0\n",
        "  !pip install prodigyopt==1.1.2\n",
        "  !pip install tensorboard\n",
        "  !pip install safetensors==0.4.4\n",
        "  !pip install altair==4.2.2\n",
        "  !pip install easygui==0.98.3\n",
        "  !pip install toml==0.10.2\n",
        "  !pip install voluptuous==0.13.1\n",
        "  !pip install huggingface-hub==0.24.5\n",
        "  !pip install imagesize==1.4.1\n",
        "  !pip install \"numpy<=2.0.0\"\n",
        "  !pip install rich==13.7.1\n",
        "  !pip install sentencepiece==0.2.0\n",
        "  !pip install deepspeed==0.16.7\n",
        "  #!pip install xformers==0.0.27.post2\n",
        "  #\n",
        "  %cd /content/zeroLR\n",
        "  !pip install -e .\n",
        "#\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "3zMXiii-6yrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST LORA FLUX DEV 1 FP8\n",
        "#DATASET = 20 IMAGES\n",
        "#REPETITIONS = 5\n",
        "#NAME FOLDER = 5_TriggerWord\n",
        "#TOTAL EPOCH = 25 (2500 max_train_steps)\n",
        "#DIM 8 / ALPHA 8\n",
        "#train_unet_only\n",
        "#LR 1E-4"
      ],
      "metadata": {
        "id": "EUPRU6NWze5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lora(arg):\n",
        "  l_arg=arg\n",
        "  !accelerate launch --num_machines 1 --num_processes 1 --num_cpu_threads_per_process 2 flux_train_network.py \\\n",
        "    --adaptive_noise_scale 0 \\\n",
        "    --ae \"/content/ae.safetensors\" \\\n",
        "    --blocks_to_swap 12 \\\n",
        "    --cache_latents \\\n",
        "    --caption_extension \".txt\" \\\n",
        "    --clip_l \"/content/clip_l.safetensors\" \\\n",
        "    --clip_skip 1 \\\n",
        "    --console_log_simple \\\n",
        "    --discrete_flow_shift 3.1582 \\\n",
        "    --fp8_base \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --gradient_checkpointing \\\n",
        "    --guidance_scale 1 \\\n",
        "    --huber_c 0.1 \\\n",
        "    --huber_schedule \"snr\" \\\n",
        "    --ip_noise_gamma 0 \\\n",
        "    --keep_tokens 1 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --logging_dir \"/content/log\" \\\n",
        "    --loss_type \"l2\" \\\n",
        "    --lr_scheduler \"constant\" \\\n",
        "    --lr_scheduler_num_cycles 1 \\\n",
        "    --lr_scheduler_power 1 \\\n",
        "    --lr_warmup_steps 0 \\\n",
        "    --max_data_loader_n_workers 2 \\\n",
        "    --max_grad_norm 1 \\\n",
        "    --max_train_steps 2500 \\\n",
        "    --min_snr_gamma 0 \\\n",
        "    --mixed_precision \"bf16\" \\\n",
        "    --model_prediction_type \"raw\" \\\n",
        "    --network_alpha 8 \\\n",
        "    --network_dim 8 \\\n",
        "    --network_dropout 0 \\\n",
        "    --network_module \"networks.lora_flux\" \\\n",
        "    --network_train_unet_only \\\n",
        "    --noise_offset 0 \\\n",
        "    --optimizer_args \"betas=(0.9, 0.999)\" \"eps=1e-8\" \"weight_decay=0.01\" \\\n",
        "    --optimizer_type \"AdamW8bit\" \\\n",
        "    --output_dir \"/content/drive/MyDrive/train\" \\\n",
        "    --persistent_data_loader_workers \\\n",
        "    --pretrained_model_name_or_path \"/content/flux1-dev-fp8.safetensors\" \\\n",
        "    --prior_loss_weight 1 \\\n",
        "    --resolution 512 \\\n",
        "    --save_every_n_epochs 1 \\\n",
        "    --save_model_as \"safetensors\" \\\n",
        "    --save_precision \"bf16\" \\\n",
        "    --save_state \\\n",
        "    --scale_weight_norms 0 \\\n",
        "    --sdpa \\\n",
        "    --seed 42 \\\n",
        "    --sigmoid_scale 1 \\\n",
        "    --t5xxl \"/content/t5xxl_fp8_e4m3fn.safetensors\" \\\n",
        "    --t5xxl_max_token_length 512 \\\n",
        "    --text_encoder_lr 0 \\\n",
        "    --timestep_sampling \"sigmoid\" \\\n",
        "    --train_batch_size 1 \\\n",
        "    --train_data_dir \"/content/drive/MyDrive/dataset\" \\\n",
        "    --unet_lr 1e-4 \\\n",
        "    --output_name \"lora_v1\" \\\n",
        "    $l_arg\n",
        "    #\n",
        "lora('--initial_epoch=1')\n",
        "#lora('--initial_epoch=5 --resume=\"/content/drive/MyDrive/train/lora_v1-000004-state\"')"
      ],
      "metadata": {
        "id": "jGpnYtUIy2Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--highvram \\\n",
        "#--apply_t5_attn_mask \\"
      ],
      "metadata": {
        "id": "CWiaHVYURmzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To continue training add the parameter:\n",
        "#--resume and indicate the last stored state. example: --resume=\"/content/drive/MyDrive/train/LoraName-xx-state\"\n",
        "#--initial_epoch=xx It is used to indicate at what number it will start saving, if the last state is 8, it will start at 9 when it continues training."
      ],
      "metadata": {
        "id": "JV_JixZTOYlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}