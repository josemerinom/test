{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJOhDdCaNupt"
      },
      "outputs": [],
      "source": [
        "from IPython.utils import capture\n",
        "with capture.capture_output() as cap:\n",
        "  #\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  #\n",
        "  %cd /content\n",
        "  #MyDrive/dataset: inside add your folder with images, example: 1_onx woman\n",
        "  !mkdir /content/drive/MyDrive/dataset\n",
        "  #MyDrive/train: here the lora and states are stored\n",
        "  !mkdir /content/drive/MyDrive/train\n",
        "  !mkdir /content/log\n",
        "  !mkdir -p /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  #git clone https://github.com/kohya-ss/sd-scripts --branch sd3\n",
        "  !curl -Lo /content/zeroLR.zip https://huggingface.co/josemerinom/flux/resolve/main/zeroLR_sd3_feb26.zip\n",
        "  #accelarator config (bp16)\n",
        "  !curl -Lo /content/default_config.yaml https://huggingface.co/josemerinom/flux/resolve/main/default_config_33.yaml\n",
        "  #vae\n",
        "  !curl -Lo /content/ae.safetensors https://huggingface.co/josemerinom/flux/resolve/main/ae.safetensors\n",
        "  #clip\n",
        "  !curl -Lo /content/clip_l.safetensors https://huggingface.co/josemerinom/flux/resolve/main/clip_l.safetensors\n",
        "  #text FP8\n",
        "  !curl -Lo /content/t5xxl_fp8_e4m3fn.safetensors https://huggingface.co/josemerinom/flux/resolve/main/t5xxl_fp8_e4m3fn.safetensors\n",
        "  #unet FP8\n",
        "  !curl -Lo /content/flux1-dev-fp8.safetensors https://huggingface.co/josemerinom/flux/resolve/main/flux1-dev-fp8.safetensors\n",
        "  #\n",
        "  !unzip -u /content/zeroLR.zip\n",
        "  !cp -r /content/default_config.yaml /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  #kohya folder (I renamed it to zeroLR)\n",
        "  %cd /content/zeroLR\n",
        "  #\n",
        "  #Uninstalling libraries to avoid conflicts\n",
        "  !pip uninstall -y peft\n",
        "  !pip uninstall -y accelerate\n",
        "  !pip uninstall -y torch torchvision torchaudio\n",
        "  #\n",
        "  #installing libraries manually (there is the option to use the req..txt file)\n",
        "  !pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "  !pip install accelerate==0.33.0\n",
        "  !pip install transformers==4.44.0\n",
        "  !pip install diffusers[torch]==0.25.0\n",
        "  !pip install ftfy==6.1.1\n",
        "  !pip install albumentations==1.3.0\n",
        "  !pip install opencv-python==4.8.1.78\n",
        "  !pip install einops==0.7.0\n",
        "  !pip install pytorch-lightning==1.9.0\n",
        "  !pip install bitsandbytes==0.44.0\n",
        "  !pip install prodigyopt==1.0\n",
        "  !pip install lion-pytorch==0.0.6\n",
        "  !pip install schedulefree==1.4\n",
        "  !pip install tensorboard\n",
        "  !pip install safetensors==0.4.4\n",
        "  !pip install altair==4.2.2\n",
        "  !pip install easygui==0.98.3\n",
        "  !pip install toml==0.10.2\n",
        "  !pip install voluptuous==0.13.1\n",
        "  !pip install huggingface-hub==0.24.5\n",
        "  !pip install imagesize==1.4.1\n",
        "  !pip install numpy<=2.0\n",
        "  !pip install rich==13.7.1\n",
        "  !pip install sentencepiece==0.2.0\n",
        "  !pip install -e .\n",
        "  #\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The following configuration is made to use 14.7gb / 15.0gb vram\n",
        "#The text_encoder is not trained (it can be activated, delete: --network_train_unet_only \\)\n",
        "#\n",
        "#If you change a parameter and the vram consumption increases:\n",
        "#Change the value of --blocks_to_swap to a higher one\n",
        "#\n",
        "#--output_name here goes the name that your training/files will take\n",
        "#\n",
        "#To continue training add the parameter:\n",
        "#--resume and indicate the last stored state. example: --resume=\"/content/drive/MyDrive/train/...state...\""
      ],
      "metadata": {
        "id": "JV_JixZTOYlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBegGb0X8CRi"
      },
      "outputs": [],
      "source": [
        "%cd /content/zeroLR\n",
        "#\n",
        "!accelerate launch --num_processes=1 --num_machines=1 --num_cpu_threads_per_process=1 flux_train_network.py \\\n",
        "  --output_name=\"test_v1\" \\\n",
        "  --adaptive_noise_scale=0 \\\n",
        "  --ae=\"/content/ae.safetensors\" \\\n",
        "  --blocks_to_swap=12 \\\n",
        "  --caption_extension=\".txt\" \\\n",
        "  --cache_latents \\\n",
        "  --clip_l=\"/content/clip_l.safetensors\" \\\n",
        "  --clip_skip=1 \\\n",
        "  --console_log_simple \\\n",
        "  --discrete_flow_shift=3.1582 \\\n",
        "  --fp8_base \\\n",
        "  --full_bf16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --guidance_scale=1 \\\n",
        "  --highvram \\\n",
        "  --huber_c=0.1 \\\n",
        "  --huber_schedule=\"snr\" \\\n",
        "  --ip_noise_gamma=0 \\\n",
        "  --keep_tokens=1 \\\n",
        "  --learning_rate=4e-4 \\\n",
        "  --logging_dir=\"/content/log\" \\\n",
        "  --loss_type=\"l2\" \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_scheduler_num_cycles=1 \\\n",
        "  --lr_scheduler_power=1 \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_data_loader_n_workers=2 \\\n",
        "  --max_train_epochs=70 \\\n",
        "  --min_snr_gamma=0 \\\n",
        "  --mixed_precision=\"bf16\" \\\n",
        "  --model_prediction_type=\"raw\" \\\n",
        "  --network_alpha=8 \\\n",
        "  --network_dim=8 \\\n",
        "  --network_dropout=0 \\\n",
        "  --network_module=networks.lora_flux \\\n",
        "  --network_train_unet_only \\\n",
        "  --noise_offset=0 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/train\" \\\n",
        "  --persistent_data_loader_workers \\\n",
        "  --pretrained_model_name_or_path=\"/content/flux1-dev-fp8.safetensors\" \\\n",
        "  --prior_loss_weight=1 \\\n",
        "  --resolution=512 \\\n",
        "  --save_every_n_epochs=1 \\\n",
        "  --save_model_as=\"safetensors\" \\\n",
        "  --save_precision=\"bf16\" \\\n",
        "  --save_state \\\n",
        "  --scale_weight_norms=0 \\\n",
        "  --sdpa \\\n",
        "  --seed=42 \\\n",
        "  --sigmoid_scale=1 \\\n",
        "  --t5xxl=\"/content/t5xxl_fp8_e4m3fn.safetensors\" \\\n",
        "  --text_encoder_lr=0 \\\n",
        "  --timestep_sampling=\"shift\" \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_data_dir=\"/content/drive/MyDrive/dataset\" \\\n",
        "  --unet_lr=4e-4 \\\n",
        "  --optimizer_args \"betas=(0.9, 0.999)\" \"eps=1e-8\" \"weight_decay=0.01\" \\\n",
        "  --optimizer_type=\"adamw8bit\" \\\n",
        "  --max_grad_norm=1 \\\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ADAFACTOR\n",
        "#--optimizer_args \"scale_parameter=False\" \"relative_step=False\" \"warmup_init=False\" \\\n",
        "#--optimizer_type=\"Adafactor\" \\\n",
        "#--max_grad_norm=0 \\\n",
        "#\n",
        "#ADAMW8BIT\n",
        "#--optimizer_args \"betas=(0.9, 0.999)\" \"eps=1e-8\" \"weight_decay=0.01\" \\\n",
        "#--optimizer_type=\"adamw8bit\" \\\n",
        "#--max_grad_norm=1 \\\n",
        "#\n",
        "#CONTINUE TRAINING\n",
        "#--resume=\"/content/drive/MyDrive/train/....\"\n",
        "#\n",
        "#IF YOU DO NOT WANT TO SAVE FOR EVERY ERA, YOU CAN CHANGE THE SAVE BY STEP\n",
        "#--save_every_n_steps=100\n",
        "#\n",
        "#OTHER PARAMETERS\n",
        "#--max_train_steps=1400 \\\n",
        "#--cache_text_encoder_outputs \\\n",
        "#--cache_text_encoder_outputs_to_disk \\\n",
        "#--network_args \"train_t5xxl=True\" \\\n",
        "#--apply_t5_attn_mask \\"
      ],
      "metadata": {
        "id": "NrOu4Zf_5f2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSRKzk9ir6xT"
      },
      "outputs": [],
      "source": [
        "#CLOSE COLAB SESSION AFTER 1 MIN\n",
        "from google.colab import runtime\n",
        "import time\n",
        "print('Done')\n",
        "time.sleep(60)\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}