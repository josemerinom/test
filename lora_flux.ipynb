{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils import capture\n",
        "with capture.capture_output() as cap:\n",
        "  #\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  #\n",
        "  %cd /content\n",
        "  !mkdir /content/drive/MyDrive/dataset\n",
        "  !mkdir /content/drive/MyDrive/train\n",
        "  !mkdir /content/log\n",
        "  !mkdir -p /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  !curl -Lo /content/ae.safetensors https://huggingface.co/josemerinom/flux/resolve/main/ae.safetensors\n",
        "  !curl -Lo /content/clip_l.safetensors https://huggingface.co/josemerinom/flux/resolve/main/clip_l.safetensors\n",
        "  !curl -Lo /content/flux1-dev-fp8.safetensors https://huggingface.co/josemerinom/flux/resolve/main/flux1-dev-fp8.safetensors\n",
        "  !curl -Lo /content/t5xxl_fp8_e4m3fn.safetensors https://huggingface.co/josemerinom/flux/resolve/main/t5xxl_fp8_e4m3fn.safetensors\n",
        "  #\n",
        "  !curl -Lo /content/default_config.yaml https://huggingface.co/josemerinom/flux/resolve/main/default_config.yaml\n",
        "  !curl -Lo /content/zeroLR.zip https://huggingface.co/josemerinom/flux/resolve/main/zeroLR_sd3_may01.zip\n",
        "  !unzip -u /content/zeroLR.zip\n",
        "  !cp -r /content/default_config.yaml /root/.cache/huggingface/accelerate/\n",
        "  #\n",
        "  !pip uninstall -y peft\n",
        "  !pip uninstall -y accelerate\n",
        "  !pip uninstall -y torch\n",
        "  !pip uninstall -y torchvision\n",
        "  !pip uninstall -y torchaudio\n",
        "  #\n",
        "  !pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "  !pip install torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "  !pip install torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "  #\n",
        "  !pip install accelerate==0.33.0\n",
        "  !pip install transformers==4.44.0\n",
        "  !pip install diffusers[torch]==0.25.0\n",
        "  !pip install ftfy==6.1.1\n",
        "  !pip install albumentations==1.3.0\n",
        "  !pip install opencv-python==4.8.1.78\n",
        "  !pip install einops==0.7.0\n",
        "  !pip install pytorch-lightning==1.9.0\n",
        "  !pip install bitsandbytes==0.44.0\n",
        "  !pip install lion-pytorch==0.0.6\n",
        "  !pip install schedulefree==1.4\n",
        "  !pip install pytorch-optimizer==3.5.0\n",
        "  !pip install prodigy-plus-schedule-free==1.9.0\n",
        "  !pip install prodigyopt==1.1.2\n",
        "  !pip install tensorboard\n",
        "  !pip install safetensors==0.4.4\n",
        "  !pip install altair==4.2.2\n",
        "  !pip install easygui==0.98.3\n",
        "  !pip install toml==0.10.2\n",
        "  !pip install voluptuous==0.13.1\n",
        "  !pip install huggingface-hub==0.24.5\n",
        "  !pip install imagesize==1.4.1\n",
        "  !pip install numpy<=2.0\n",
        "  !pip install rich==13.7.1\n",
        "  !pip install sentencepiece==0.2.0\n",
        "  !pip install deepspeed==0.16.7\n",
        "  !pip install xformers==0.0.27.post2\n",
        "  #\n",
        "  %cd /content/zeroLR\n",
        "  !pip install -e .\n",
        "  #\n",
        "print(\"done\")"
      ],
      "metadata": {
        "id": "3zMXiii-6yrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/zeroLR\n",
        "#\n",
        "def lora(name,arg):\n",
        "  l_name=name\n",
        "  l_arg=arg\n",
        "  print(l_arg)\n",
        "  !accelerate launch --num_processes=1 --num_machines=1 --num_cpu_threads_per_process=1 flux_train_network.py \\\n",
        "    --adaptive_noise_scale=0 \\\n",
        "    --ae=\"/content/ae.safetensors\" \\\n",
        "    --apply_t5_attn_mask \\\n",
        "    --blocks_to_swap=18 \\\n",
        "    --cache_latents \\\n",
        "    --caption_extension=\".txt\" \\\n",
        "    --clip_l=\"/content/clip_l.safetensors\" \\\n",
        "    --clip_skip=1 \\\n",
        "    --console_log_simple \\\n",
        "    --discrete_flow_shift=3 \\\n",
        "    --fp8_base \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --gradient_checkpointing \\\n",
        "    --guidance_scale=1 \\\n",
        "    --huber_c=0.1 \\\n",
        "    --huber_schedule=\"snr\" \\\n",
        "    --ip_noise_gamma=0 \\\n",
        "    --keep_tokens=0 \\\n",
        "    --learning_rate=2e-4 \\\n",
        "    --logging_dir=\"/content/log\" \\\n",
        "    --loss_type=\"l2\" \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_scheduler_num_cycles=1 \\\n",
        "    --lr_scheduler_power=1 \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_data_loader_n_workers=0 \\\n",
        "    --max_grad_norm=1 \\\n",
        "    --max_train_steps=2000 \\\n",
        "    --min_snr_gamma=0 \\\n",
        "    --mixed_precision=\"bf16\" \\\n",
        "    --model_prediction_type=\"raw\" \\\n",
        "    --network_alpha=16 \\\n",
        "    --network_dim=16 \\\n",
        "    --network_dropout=0 \\\n",
        "    --network_module=networks.lora_flux \\\n",
        "    --network_train_unet_only \\\n",
        "    --noise_offset=0 \\\n",
        "    --optimizer_args \"betas=(0.9, 0.999)\" \"eps=1e-8\" \"weight_decay=0.01\" \\\n",
        "    --optimizer_type=\"AdamW8bit\" \\\n",
        "    --output_dir=\"/content/drive/MyDrive/train\" \\\n",
        "    --output_name=$l_name \\\n",
        "    --pretrained_model_name_or_path=\"/content/flux1-dev-fp8.safetensors\" \\\n",
        "    --prior_loss_weight=1 \\\n",
        "    --resolution=512 \\\n",
        "    --save_every_n_epochs=1 \\\n",
        "    --save_model_as=\"safetensors\" \\\n",
        "    --save_precision=\"bf16\" \\\n",
        "    --save_state \\\n",
        "    --scale_weight_norms=0 \\\n",
        "    --seed=1 \\\n",
        "    --sigmoid_scale=1 \\\n",
        "    --t5xxl=\"/content/t5xxl_fp8_e4m3fn.safetensors\" \\\n",
        "    --t5xxl_max_token_length=512 \\\n",
        "    --text_encoder_lr=0 \\\n",
        "    --timestep_sampling=\"sigmoid\" \\\n",
        "    --train_batch_size=2 \\\n",
        "    --train_data_dir=\"/content/drive/MyDrive/dataset\" \\\n",
        "    --unet_lr=2e-4 \\\n",
        "    --xformers \\\n",
        "    $l_arg\n",
        "    #\n",
        "lora('TEST_PART_A','--initial_epoch=1')\n",
        "#lora('TEST_PART_B','--initial_epoch=19 --resume=\"/content/drive/MyDrive/train/TEST_PART_A-000018-state\"')\n",
        "#lora('TEST_PART_C','--initial_epoch=35 --resume=\"/content/drive/MyDrive/train/TEST_PART_B-000034-state\"')"
      ],
      "metadata": {
        "id": "S5ISdszz7hQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To continue training add the parameter:\n",
        "#--resume and indicate the last stored state. example: --resume=\"/content/drive/MyDrive/train/LoraName-xx-state\"\n",
        "#--initial_epoch=xx It is used to indicate at what number it will start saving, if the last state is 8, it will start at 9 when it continues training."
      ],
      "metadata": {
        "id": "JV_JixZTOYlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}