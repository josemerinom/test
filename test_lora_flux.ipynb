{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-FHAs-Gu4KHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd07192a-a3a9-40eb-c02f-ecf1d0957668"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "#\n",
        "!mkdir /content/drive/MyDrive/dataset\n",
        "!mkdir /content/drive/MyDrive/train\n",
        "!mkdir /content/log\n",
        "#\n",
        "!git clone https://github.com/kohya-ss/sd-scripts --branch sd3"
      ],
      "metadata": {
        "id": "RsKKs5JL4OsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2979a286-6168-4ba3-9644-10270a2e8cd6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'sd-scripts'...\n",
            "remote: Enumerating objects: 9036, done.\u001b[K\n",
            "remote: Counting objects: 100% (527/527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 9036 (delta 488), reused 426 (delta 426), pack-reused 8509 (from 4)\u001b[K\n",
            "Receiving objects: 100% (9036/9036), 11.44 MiB | 11.34 MiB/s, done.\n",
            "Resolving deltas: 100% (6516/6516), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sd-scripts\n",
        "#\n",
        "!pip uninstall -y peft\n",
        "!pip uninstall -y accelerate\n",
        "!pip uninstall -y torch torchvision torchaudio torchtext\n",
        "#\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "#\n",
        "!pip install accelerate==0.33.0\n",
        "!pip install transformers==4.44.0\n",
        "!pip install diffusers[torch]==0.25.0\n",
        "!pip install ftfy==6.1.1\n",
        "!pip install albumentations==1.3.0\n",
        "!pip install opencv-python==4.8.1.78\n",
        "!pip install einops==0.7.0\n",
        "!pip install pytorch-lightning==1.9.0\n",
        "!pip install bitsandbytes==0.44.0\n",
        "#!pip install prodigyopt==1.0\n",
        "#!pip install lion-pytorch==0.0.6\n",
        "!pip install schedulefree==1.4\n",
        "!pip install tensorboard\n",
        "!pip install safetensors==0.4.4\n",
        "!pip install altair==4.2.2\n",
        "!pip install easygui==0.98.3\n",
        "!pip install toml==0.10.2\n",
        "!pip install voluptuous==0.13.1\n",
        "!pip install huggingface-hub==0.24.5\n",
        "!pip install imagesize==1.4.1\n",
        "!pip install numpy<=2.0\n",
        "!pip install rich==13.7.1\n",
        "!pip install sentencepiece==0.2.0\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "0vX_F_c44ijT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00738bde-92c5-4cda-9d76-247463c45dc2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sd-scripts\n",
            "Found existing installation: peft 0.14.0\n",
            "Uninstalling peft-0.14.0:\n",
            "  Successfully uninstalled peft-0.14.0\n",
            "Found existing installation: accelerate 1.2.1\n",
            "Uninstalling accelerate-1.2.1:\n",
            "  Successfully uninstalled accelerate-1.2.1\n",
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Found existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.0%2Bcu124-cp311-cp311-linux_x86_64.whl (797.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (24.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.4/883.4 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.4.2.65 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.2.65-py3-none-manylinux2014_x86_64.whl (363.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.0.44 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.0.44-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.119 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.119-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.0.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.0.99-py3-none-manylinux2014_x86_64.whl (128.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.0.142 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.0.142-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.99 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.61:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "Successfully installed nvidia-cublas-cu12-12.4.2.65 nvidia-cuda-cupti-cu12-12.4.99 nvidia-cuda-nvrtc-cu12-12.4.99 nvidia-cuda-runtime-cu12-12.4.99 nvidia-cufft-cu12-11.2.0.44 nvidia-curand-cu12-10.3.5.119 nvidia-cusolver-cu12-11.6.0.99 nvidia-cusparse-cu12-12.3.0.142 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.4.99 torch-2.4.0+cu124 torchaudio-2.4.0+cu124 torchvision-0.19.0+cu124 triton-3.0.0\n",
            "Collecting accelerate==0.33.0\n",
            "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (2.4.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.2.65)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (11.2.0.44)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (10.3.5.119)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (11.6.0.99)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.3.0.142)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (12.4.99)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.33.0) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.12.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->accelerate==0.33.0) (1.3.0)\n",
            "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "Successfully installed accelerate-0.33.0\n",
            "Collecting transformers==4.44.0\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (0.5.2)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.0)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.0) (2024.12.14)\n",
            "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed tokenizers-0.19.1 transformers-4.44.0\n",
            "Collecting diffusers==0.25.0 (from diffusers[torch]==0.25.0)\n",
            "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (0.5.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.25.0->diffusers[torch]==0.25.0) (11.1.0)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (2.4.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from diffusers[torch]==0.25.0) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0->diffusers[torch]==0.25.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.2.65)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.2.0.44)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (10.3.5.119)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (11.6.0.99)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.3.0.142)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (12.4.99)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers[torch]==0.25.0) (3.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.25.0->diffusers[torch]==0.25.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4->diffusers[torch]==0.25.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.4->diffusers[torch]==0.25.0) (1.3.0)\n",
            "Downloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.32.2\n",
            "    Uninstalling diffusers-0.32.2:\n",
            "      Successfully uninstalled diffusers-0.32.2\n",
            "Successfully installed diffusers-0.25.0\n",
            "Collecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.1.1) (0.2.13)\n",
            "Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n",
            "Collecting albumentations==1.3.0\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (0.25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (6.0.2)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.0)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.3.0) (4.11.0.86)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.12.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2025.1.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.5.0)\n",
            "Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed albumentations-1.3.0 qudida-0.0.4\n",
            "Collecting opencv-python==4.8.1.78\n",
            "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python==4.8.1.78) (1.26.4)\n",
            "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "Successfully installed opencv-python-4.8.1.78\n",
            "Collecting einops==0.7.0\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "Successfully installed einops-0.7.0\n",
            "Collecting pytorch-lightning==1.9.0\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (2.4.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning==1.9.0)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==1.9.0) (4.12.2)\n",
            "Collecting lightning-utilities>=0.4.2 (from pytorch-lightning==1.9.0)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.11.11)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.4.2->pytorch-lightning==1.9.0) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.2.65)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.2.0.44)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (10.3.5.119)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (11.6.0.99)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.3.0.142)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (12.4.99)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->pytorch-lightning==1.9.0) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.0) (3.10)\n",
            "Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.9 pytorch-lightning-1.9.0 torchmetrics-1.6.1\n",
            "Collecting bitsandbytes==0.44.0\n",
            "  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (2.4.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.44.0) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.2.65)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.2.0.44)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (10.3.5.119)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (11.6.0.99)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.3.0.142)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.99)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (12.4.99)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.44.0) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.44.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->bitsandbytes==0.44.0) (1.3.0)\n",
            "Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.0\n",
            "Collecting schedulefree==1.4\n",
            "  Downloading schedulefree-1.4.tar.gz (22 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: schedulefree\n",
            "  Building wheel for schedulefree (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for schedulefree: filename=schedulefree-1.4-py3-none-any.whl size=39303 sha256=9024f7f9919844723373c58c9b17810b5b487a32ef3b44f45c8eb3ddf3fcff45\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/77/aa/edc982c812bbfb7d516f4de2b373eaafe450b27cd7e4f041ea\n",
            "Successfully built schedulefree\n",
            "Installing collected packages: schedulefree\n",
            "Successfully installed schedulefree-1.4\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Collecting safetensors==0.4.4\n",
            "  Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading safetensors-0.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: safetensors\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.5.2\n",
            "    Uninstalling safetensors-0.5.2:\n",
            "      Successfully uninstalled safetensors-0.5.2\n",
            "Successfully installed safetensors-0.4.4\n",
            "Collecting altair==4.2.2\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from altair==4.2.2) (0.12.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair==4.2.2) (0.22.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair==4.2.2) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair==4.2.2) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair==4.2.2) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=3.0->altair==4.2.2) (4.12.2)\n",
            "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: altair\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.5.0\n",
            "    Uninstalling altair-5.5.0:\n",
            "      Successfully uninstalled altair-5.5.0\n",
            "Successfully installed altair-4.2.2\n",
            "Collecting easygui==0.98.3\n",
            "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: easygui\n",
            "Successfully installed easygui-0.98.3\n",
            "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (0.10.2)\n",
            "Collecting voluptuous==0.13.1\n",
            "  Downloading voluptuous-0.13.1-py3-none-any.whl.metadata (20 kB)\n",
            "Downloading voluptuous-0.13.1-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: voluptuous\n",
            "Successfully installed voluptuous-0.13.1\n",
            "Collecting huggingface-hub==0.24.5\n",
            "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.24.5) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.24.5) (2024.12.14)\n",
            "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "Successfully installed huggingface-hub-0.24.5\n",
            "Requirement already satisfied: imagesize==1.4.1 in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
            "/bin/bash: line 1: =2.0: No such file or directory\n",
            "Collecting rich==13.7.1\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.7.1) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1) (0.1.2)\n",
            "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rich\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "Successfully installed rich-13.7.1\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Obtaining file:///content/sd-scripts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: library\n",
            "  Running setup.py develop for library\n",
            "Successfully installed library-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config"
      ],
      "metadata": {
        "id": "UjjCEB1k4vby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f163887-f3be-4cbd-ebe5-29da86acf1f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r----------------------------------------------------------------------------------------------------In which compute environment are you running?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mThis machine\u001b[0m\r\n",
            "    AWS (Amazon SageMaker)\n",
            "\u001b[2A\u001b[?25l0\n",
            "\u001b[32mThis machine\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------Which type of machine are you using?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mNo distributed training\u001b[0m\n",
            "    multi-CPU\n",
            "    multi-XPU\n",
            "    multi-GPU\n",
            "    multi-NPU\n",
            "    multi-MLU\n",
            "    multi-MUSA\n",
            "    TPU\n",
            "\u001b[8A\u001b[?25l0\n",
            "\u001b[32mNo distributed training\u001b[0m\n",
            "\u001b[?25hDo you want to run your training on CPU only (even if a GPU / Apple Silicon / Ascend NPU device is available)? [yes/NO]:no\n",
            "Do you wish to optimize your script with torch dynamo?[yes/NO]:no\n",
            "Do you want to use DeepSpeed? [yes/NO]: no\n",
            "What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:all\n",
            "Would you like to enable numa efficiency? (Currently only supported on NVIDIA hardware). [yes/NO]: no\n",
            "----------------------------------------------------------------------------------------------------Do you wish to use FP16 or BF16 (mixed precision)?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mno\u001b[0m\n",
            "    fp16\n",
            "    bf16\n",
            "    fp8\n",
            "\u001b[4A\u001b[?25l2\n",
            "\u001b[32mbf16\u001b[0m\n",
            "\u001b[?25haccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sd-scripts\n",
        "#\n",
        "# blocks_to_swap=22\n",
        "# System RAM 12.5 / 12.7 GB\n",
        "# GPU RAM 11.5 / 15.0 GB\n",
        "#\n",
        "!accelerate launch --num_processes=1 --num_machines=1 --num_cpu_threads_per_process=1 flux_train_network.py \\\n",
        "  --adaptive_noise_scale=0 \\\n",
        "  --ae=\"/content/drive/MyDrive/zero/models/vae/ae.safetensors\" \\\n",
        "  --apply_t5_attn_mask \\\n",
        "  --blocks_to_swap=22 \\\n",
        "  --cache_latents \\\n",
        "  --caption_extension=\".txt\" \\\n",
        "  --clip_l=\"/content/drive/MyDrive/zero/models/clip/clip_l.safetensors\" \\\n",
        "  --clip_skip=1 \\\n",
        "  --console_log_simple \\\n",
        "  --discrete_flow_shift=3.1582 \\\n",
        "  --fp8_base \\\n",
        "  --full_bf16 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --guidance_scale=1 \\\n",
        "  --highvram \\\n",
        "  --huber_c=0.1 \\\n",
        "  --huber_schedule=\"snr\" \\\n",
        "  --ip_noise_gamma=0 \\\n",
        "  --keep_tokens=1 \\\n",
        "  --logging_dir=\"/content/log\" \\\n",
        "  --loss_type=\"l2\" \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_scheduler_num_cycles=1 \\\n",
        "  --lr_scheduler_power=1 \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_data_loader_n_workers=0 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --max_train_epochs=100 \\\n",
        "  --min_snr_gamma=0 \\\n",
        "  --mixed_precision=\"bf16\" \\\n",
        "  --model_prediction_type=\"raw\" \\\n",
        "  --network_alpha=8 \\\n",
        "  --network_dim=8 \\\n",
        "  --network_dropout=0 \\\n",
        "  --network_module=networks.lora_flux \\\n",
        "  --network_train_unet_only \\\n",
        "  --noise_offset=0 \\\n",
        "  --optimizer_args \"betas=(0.9, 0.999)\" \"eps=1e-8\" \"weight_decay=0.01\" \\\n",
        "  --optimizer_type=\"adamw8bit\" \\\n",
        "  --output_dir=\"/content/drive/MyDrive/train\" \\\n",
        "  --output_name=\"my_first_flux\" \\\n",
        "  --pretrained_model_name_or_path=\"/content/drive/MyDrive/zero/models/checkpoints/flux1-dev-fp8.safetensors\" \\\n",
        "  --prior_loss_weight=1 \\\n",
        "  --resolution=512 \\\n",
        "  --save_every_n_epochs=1 \\\n",
        "  --save_model_as=\"safetensors\" \\\n",
        "  --save_precision=\"bf16\" \\\n",
        "  --save_state \\\n",
        "  --scale_weight_norms=0 \\\n",
        "  --sdpa \\\n",
        "  --seed=1 \\\n",
        "  --sigmoid_scale=1 \\\n",
        "  --t5xxl=\"/content/drive/MyDrive/zero/models/clip/t5xxl_fp8_e4m3fn.safetensors\" \\\n",
        "  --text_encoder_lr=0 \\\n",
        "  --timestep_sampling=\"shift\" \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_data_dir=\"/content/drive/MyDrive/dataset\" \\\n",
        "  --learning_rate=2e-4 \\\n",
        "  --unet_lr=2e-4"
      ],
      "metadata": {
        "id": "c1efNNiE4yDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebd475f-fa3c-426d-fcf5-04e445bbffb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "special_tokens_map.json: 100% 389/389 [00:00<00:00, 2.37MB/s]\n",
            "tokenizer.json: 100% 2.22M/2.22M [00:00<00:00, 14.6MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 1.86k/1.86k [00:00<00:00, 14.7MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 24.0MB/s]\n",
            "special_tokens_map.json: 100% 1.79k/1.79k [00:00<00:00, 13.6MB/s]\n",
            "config.json: 100% 593/593 [00:00<00:00, 5.00MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Using DreamBooth method.\n",
            "prepare images.\n",
            "get image size from name of cache files\n",
            "100% 20/20 [00:00<00:00, 251910.15it/s]\n",
            "set image size from cache files: 0/20\n",
            "found directory /content/drive/MyDrive/dataset/1_zkvjqx woman contains 20 image files\n",
            "read caption: 100% 20/20 [00:00<00:00, 4332.73it/s]\n",
            "No caption file found for 20 images. Training will continue without captions for these images. If class token exists, it will be used. / 20枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_01.jpg\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_02.jpg\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_03.jpg\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_04.jpg\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_05.jpg\n",
            "/content/drive/MyDrive/dataset/1_zkvjqx woman/zkvjqx_06.jpg... and 15 more\n",
            "20 train images with repeats.\n",
            "0 reg images with repeats.\n",
            "no regularization images / 正則化画像が見つかりませんでした\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (512, 512)\n",
            "  enable_bucket: False\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/dataset/1_zkvjqx woman\"\n",
            "    image_count: 20\n",
            "    num_repeats: 1\n",
            "    shuffle_caption: False\n",
            "    keep_tokens: 1\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epochs: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    caption_prefix: None\n",
            "    caption_suffix: None\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    alpha_mask: False\n",
            "    custom_attributes: {}\n",
            "    is_reg: False\n",
            "    class_tokens: zkvjqx woman\n",
            "    caption_extension: .txt\n",
            "\n",
            "\n",
            "[Prepare dataset 0]\n",
            "loading image sizes.\n",
            "100% 20/20 [00:10<00:00,  1.92it/s]\n",
            "prepare dataset\n",
            "preparing accelerator\n",
            "accelerator device: cuda\n",
            "Checking the state dict: Diffusers or BFL, dev or schnell\n",
            "Building Flux model dev from BFL checkpoint\n",
            "Loading state dict from /content/drive/MyDrive/zero/models/checkpoints/flux1-dev-fp8.safetensors\n",
            "Loaded Flux: _IncompatibleKeys(missing_keys=[], unexpected_keys=['text_encoders.clip_l.logit_scale', 'text_encoders.clip_l.transformer.text_model.embeddings.position_embedding.weight', 'text_encoders.clip_l.transformer.text_model.embeddings.token_embedding.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_encoders.clip_l.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_encoders.clip_l.transformer.text_model.final_layer_norm.bias', 'text_encoders.clip_l.transformer.text_model.final_layer_norm.weight', 'text_encoders.clip_l.transformer.text_projection.weight', 'text_encoders.t5xxl.logit_scale', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.0.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.1.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.10.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.11.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.12.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.13.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.14.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.15.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.16.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.17.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.18.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.19.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.2.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.20.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.21.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.22.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.23.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.3.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.4.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.5.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.6.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.7.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.8.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.0.SelfAttention.k.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.0.SelfAttention.o.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.0.SelfAttention.q.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.0.SelfAttention.v.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.0.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'text_encoders.t5xxl.transformer.encoder.block.9.layer.1.layer_norm.weight', 'text_encoders.t5xxl.transformer.encoder.final_layer_norm.weight', 'text_encoders.t5xxl.transformer.shared.weight', 'vae.decoder.conv_in.bias', 'vae.decoder.conv_in.weight', 'vae.decoder.conv_out.bias', 'vae.decoder.conv_out.weight', 'vae.decoder.mid.attn_1.k.bias', 'vae.decoder.mid.attn_1.k.weight', 'vae.decoder.mid.attn_1.norm.bias', 'vae.decoder.mid.attn_1.norm.weight', 'vae.decoder.mid.attn_1.proj_out.bias', 'vae.decoder.mid.attn_1.proj_out.weight', 'vae.decoder.mid.attn_1.q.bias', 'vae.decoder.mid.attn_1.q.weight', 'vae.decoder.mid.attn_1.v.bias', 'vae.decoder.mid.attn_1.v.weight', 'vae.decoder.mid.block_1.conv1.bias', 'vae.decoder.mid.block_1.conv1.weight', 'vae.decoder.mid.block_1.conv2.bias', 'vae.decoder.mid.block_1.conv2.weight', 'vae.decoder.mid.block_1.norm1.bias', 'vae.decoder.mid.block_1.norm1.weight', 'vae.decoder.mid.block_1.norm2.bias', 'vae.decoder.mid.block_1.norm2.weight', 'vae.decoder.mid.block_2.conv1.bias', 'vae.decoder.mid.block_2.conv1.weight', 'vae.decoder.mid.block_2.conv2.bias', 'vae.decoder.mid.block_2.conv2.weight', 'vae.decoder.mid.block_2.norm1.bias', 'vae.decoder.mid.block_2.norm1.weight', 'vae.decoder.mid.block_2.norm2.bias', 'vae.decoder.mid.block_2.norm2.weight', 'vae.decoder.norm_out.bias', 'vae.decoder.norm_out.weight', 'vae.decoder.up.0.block.0.conv1.bias', 'vae.decoder.up.0.block.0.conv1.weight', 'vae.decoder.up.0.block.0.conv2.bias', 'vae.decoder.up.0.block.0.conv2.weight', 'vae.decoder.up.0.block.0.nin_shortcut.bias', 'vae.decoder.up.0.block.0.nin_shortcut.weight', 'vae.decoder.up.0.block.0.norm1.bias', 'vae.decoder.up.0.block.0.norm1.weight', 'vae.decoder.up.0.block.0.norm2.bias', 'vae.decoder.up.0.block.0.norm2.weight', 'vae.decoder.up.0.block.1.conv1.bias', 'vae.decoder.up.0.block.1.conv1.weight', 'vae.decoder.up.0.block.1.conv2.bias', 'vae.decoder.up.0.block.1.conv2.weight', 'vae.decoder.up.0.block.1.norm1.bias', 'vae.decoder.up.0.block.1.norm1.weight', 'vae.decoder.up.0.block.1.norm2.bias', 'vae.decoder.up.0.block.1.norm2.weight', 'vae.decoder.up.0.block.2.conv1.bias', 'vae.decoder.up.0.block.2.conv1.weight', 'vae.decoder.up.0.block.2.conv2.bias', 'vae.decoder.up.0.block.2.conv2.weight', 'vae.decoder.up.0.block.2.norm1.bias', 'vae.decoder.up.0.block.2.norm1.weight', 'vae.decoder.up.0.block.2.norm2.bias', 'vae.decoder.up.0.block.2.norm2.weight', 'vae.decoder.up.1.block.0.conv1.bias', 'vae.decoder.up.1.block.0.conv1.weight', 'vae.decoder.up.1.block.0.conv2.bias', 'vae.decoder.up.1.block.0.conv2.weight', 'vae.decoder.up.1.block.0.nin_shortcut.bias', 'vae.decoder.up.1.block.0.nin_shortcut.weight', 'vae.decoder.up.1.block.0.norm1.bias', 'vae.decoder.up.1.block.0.norm1.weight', 'vae.decoder.up.1.block.0.norm2.bias', 'vae.decoder.up.1.block.0.norm2.weight', 'vae.decoder.up.1.block.1.conv1.bias', 'vae.decoder.up.1.block.1.conv1.weight', 'vae.decoder.up.1.block.1.conv2.bias', 'vae.decoder.up.1.block.1.conv2.weight', 'vae.decoder.up.1.block.1.norm1.bias', 'vae.decoder.up.1.block.1.norm1.weight', 'vae.decoder.up.1.block.1.norm2.bias', 'vae.decoder.up.1.block.1.norm2.weight', 'vae.decoder.up.1.block.2.conv1.bias', 'vae.decoder.up.1.block.2.conv1.weight', 'vae.decoder.up.1.block.2.conv2.bias', 'vae.decoder.up.1.block.2.conv2.weight', 'vae.decoder.up.1.block.2.norm1.bias', 'vae.decoder.up.1.block.2.norm1.weight', 'vae.decoder.up.1.block.2.norm2.bias', 'vae.decoder.up.1.block.2.norm2.weight', 'vae.decoder.up.1.upsample.conv.bias', 'vae.decoder.up.1.upsample.conv.weight', 'vae.decoder.up.2.block.0.conv1.bias', 'vae.decoder.up.2.block.0.conv1.weight', 'vae.decoder.up.2.block.0.conv2.bias', 'vae.decoder.up.2.block.0.conv2.weight', 'vae.decoder.up.2.block.0.norm1.bias', 'vae.decoder.up.2.block.0.norm1.weight', 'vae.decoder.up.2.block.0.norm2.bias', 'vae.decoder.up.2.block.0.norm2.weight', 'vae.decoder.up.2.block.1.conv1.bias', 'vae.decoder.up.2.block.1.conv1.weight', 'vae.decoder.up.2.block.1.conv2.bias', 'vae.decoder.up.2.block.1.conv2.weight', 'vae.decoder.up.2.block.1.norm1.bias', 'vae.decoder.up.2.block.1.norm1.weight', 'vae.decoder.up.2.block.1.norm2.bias', 'vae.decoder.up.2.block.1.norm2.weight', 'vae.decoder.up.2.block.2.conv1.bias', 'vae.decoder.up.2.block.2.conv1.weight', 'vae.decoder.up.2.block.2.conv2.bias', 'vae.decoder.up.2.block.2.conv2.weight', 'vae.decoder.up.2.block.2.norm1.bias', 'vae.decoder.up.2.block.2.norm1.weight', 'vae.decoder.up.2.block.2.norm2.bias', 'vae.decoder.up.2.block.2.norm2.weight', 'vae.decoder.up.2.upsample.conv.bias', 'vae.decoder.up.2.upsample.conv.weight', 'vae.decoder.up.3.block.0.conv1.bias', 'vae.decoder.up.3.block.0.conv1.weight', 'vae.decoder.up.3.block.0.conv2.bias', 'vae.decoder.up.3.block.0.conv2.weight', 'vae.decoder.up.3.block.0.norm1.bias', 'vae.decoder.up.3.block.0.norm1.weight', 'vae.decoder.up.3.block.0.norm2.bias', 'vae.decoder.up.3.block.0.norm2.weight', 'vae.decoder.up.3.block.1.conv1.bias', 'vae.decoder.up.3.block.1.conv1.weight', 'vae.decoder.up.3.block.1.conv2.bias', 'vae.decoder.up.3.block.1.conv2.weight', 'vae.decoder.up.3.block.1.norm1.bias', 'vae.decoder.up.3.block.1.norm1.weight', 'vae.decoder.up.3.block.1.norm2.bias', 'vae.decoder.up.3.block.1.norm2.weight', 'vae.decoder.up.3.block.2.conv1.bias', 'vae.decoder.up.3.block.2.conv1.weight', 'vae.decoder.up.3.block.2.conv2.bias', 'vae.decoder.up.3.block.2.conv2.weight', 'vae.decoder.up.3.block.2.norm1.bias', 'vae.decoder.up.3.block.2.norm1.weight', 'vae.decoder.up.3.block.2.norm2.bias', 'vae.decoder.up.3.block.2.norm2.weight', 'vae.decoder.up.3.upsample.conv.bias', 'vae.decoder.up.3.upsample.conv.weight', 'vae.encoder.conv_in.bias', 'vae.encoder.conv_in.weight', 'vae.encoder.conv_out.bias', 'vae.encoder.conv_out.weight', 'vae.encoder.down.0.block.0.conv1.bias', 'vae.encoder.down.0.block.0.conv1.weight', 'vae.encoder.down.0.block.0.conv2.bias', 'vae.encoder.down.0.block.0.conv2.weight', 'vae.encoder.down.0.block.0.norm1.bias', 'vae.encoder.down.0.block.0.norm1.weight', 'vae.encoder.down.0.block.0.norm2.bias', 'vae.encoder.down.0.block.0.norm2.weight', 'vae.encoder.down.0.block.1.conv1.bias', 'vae.encoder.down.0.block.1.conv1.weight', 'vae.encoder.down.0.block.1.conv2.bias', 'vae.encoder.down.0.block.1.conv2.weight', 'vae.encoder.down.0.block.1.norm1.bias', 'vae.encoder.down.0.block.1.norm1.weight', 'vae.encoder.down.0.block.1.norm2.bias', 'vae.encoder.down.0.block.1.norm2.weight', 'vae.encoder.down.0.downsample.conv.bias', 'vae.encoder.down.0.downsample.conv.weight', 'vae.encoder.down.1.block.0.conv1.bias', 'vae.encoder.down.1.block.0.conv1.weight', 'vae.encoder.down.1.block.0.conv2.bias', 'vae.encoder.down.1.block.0.conv2.weight', 'vae.encoder.down.1.block.0.nin_shortcut.bias', 'vae.encoder.down.1.block.0.nin_shortcut.weight', 'vae.encoder.down.1.block.0.norm1.bias', 'vae.encoder.down.1.block.0.norm1.weight', 'vae.encoder.down.1.block.0.norm2.bias', 'vae.encoder.down.1.block.0.norm2.weight', 'vae.encoder.down.1.block.1.conv1.bias', 'vae.encoder.down.1.block.1.conv1.weight', 'vae.encoder.down.1.block.1.conv2.bias', 'vae.encoder.down.1.block.1.conv2.weight', 'vae.encoder.down.1.block.1.norm1.bias', 'vae.encoder.down.1.block.1.norm1.weight', 'vae.encoder.down.1.block.1.norm2.bias', 'vae.encoder.down.1.block.1.norm2.weight', 'vae.encoder.down.1.downsample.conv.bias', 'vae.encoder.down.1.downsample.conv.weight', 'vae.encoder.down.2.block.0.conv1.bias', 'vae.encoder.down.2.block.0.conv1.weight', 'vae.encoder.down.2.block.0.conv2.bias', 'vae.encoder.down.2.block.0.conv2.weight', 'vae.encoder.down.2.block.0.nin_shortcut.bias', 'vae.encoder.down.2.block.0.nin_shortcut.weight', 'vae.encoder.down.2.block.0.norm1.bias', 'vae.encoder.down.2.block.0.norm1.weight', 'vae.encoder.down.2.block.0.norm2.bias', 'vae.encoder.down.2.block.0.norm2.weight', 'vae.encoder.down.2.block.1.conv1.bias', 'vae.encoder.down.2.block.1.conv1.weight', 'vae.encoder.down.2.block.1.conv2.bias', 'vae.encoder.down.2.block.1.conv2.weight', 'vae.encoder.down.2.block.1.norm1.bias', 'vae.encoder.down.2.block.1.norm1.weight', 'vae.encoder.down.2.block.1.norm2.bias', 'vae.encoder.down.2.block.1.norm2.weight', 'vae.encoder.down.2.downsample.conv.bias', 'vae.encoder.down.2.downsample.conv.weight', 'vae.encoder.down.3.block.0.conv1.bias', 'vae.encoder.down.3.block.0.conv1.weight', 'vae.encoder.down.3.block.0.conv2.bias', 'vae.encoder.down.3.block.0.conv2.weight', 'vae.encoder.down.3.block.0.norm1.bias', 'vae.encoder.down.3.block.0.norm1.weight', 'vae.encoder.down.3.block.0.norm2.bias', 'vae.encoder.down.3.block.0.norm2.weight', 'vae.encoder.down.3.block.1.conv1.bias', 'vae.encoder.down.3.block.1.conv1.weight', 'vae.encoder.down.3.block.1.conv2.bias', 'vae.encoder.down.3.block.1.conv2.weight', 'vae.encoder.down.3.block.1.norm1.bias', 'vae.encoder.down.3.block.1.norm1.weight', 'vae.encoder.down.3.block.1.norm2.bias', 'vae.encoder.down.3.block.1.norm2.weight', 'vae.encoder.mid.attn_1.k.bias', 'vae.encoder.mid.attn_1.k.weight', 'vae.encoder.mid.attn_1.norm.bias', 'vae.encoder.mid.attn_1.norm.weight', 'vae.encoder.mid.attn_1.proj_out.bias', 'vae.encoder.mid.attn_1.proj_out.weight', 'vae.encoder.mid.attn_1.q.bias', 'vae.encoder.mid.attn_1.q.weight', 'vae.encoder.mid.attn_1.v.bias', 'vae.encoder.mid.attn_1.v.weight', 'vae.encoder.mid.block_1.conv1.bias', 'vae.encoder.mid.block_1.conv1.weight', 'vae.encoder.mid.block_1.conv2.bias', 'vae.encoder.mid.block_1.conv2.weight', 'vae.encoder.mid.block_1.norm1.bias', 'vae.encoder.mid.block_1.norm1.weight', 'vae.encoder.mid.block_1.norm2.bias', 'vae.encoder.mid.block_1.norm2.weight', 'vae.encoder.mid.block_2.conv1.bias', 'vae.encoder.mid.block_2.conv1.weight', 'vae.encoder.mid.block_2.conv2.bias', 'vae.encoder.mid.block_2.conv2.weight', 'vae.encoder.mid.block_2.norm1.bias', 'vae.encoder.mid.block_2.norm1.weight', 'vae.encoder.mid.block_2.norm2.bias', 'vae.encoder.mid.block_2.norm2.weight', 'vae.encoder.norm_out.bias', 'vae.encoder.norm_out.weight'])\n",
            "Loaded fp8 FLUX model\n",
            "enable block swap: blocks_to_swap=22\n",
            "FLUX: Block swap enabled. Swapping 22 blocks, double blocks: 11, single blocks: 22.\n",
            "Building CLIP-L\n",
            "Loading state dict from /content/drive/MyDrive/zero/models/clip/clip_l.safetensors\n",
            "Loaded CLIP-L: <All keys matched successfully>\n",
            "Loading state dict from /content/drive/MyDrive/zero/models/clip/t5xxl_fp8_e4m3fn.safetensors\n",
            "Loaded T5xxl: <All keys matched successfully>\n",
            "Loaded fp8 T5XXL model\n",
            "Building AutoEncoder\n",
            "Loading state dict from /content/drive/MyDrive/zero/models/vae/ae.safetensors\n",
            "Loaded AE: <All keys matched successfully>\n",
            "import network module: networks.lora_flux\n",
            "[Dataset 0]\n",
            "caching latents with caching strategy.\n",
            "caching latents...\n",
            "100% 20/20 [00:11<00:00,  1.68it/s]\n",
            "create LoRA network. base dim (rank): 8, alpha: 8.0\n",
            "neuron dropout: p=0.0, rank dropout: p=None, module dropout: p=None\n",
            "train all blocks only\n",
            "create LoRA for Text Encoder 1:\n",
            "create LoRA for Text Encoder 1: 72 modules.\n",
            "create LoRA for FLUX all blocks: 304 modules.\n",
            "enable LoRA for U-Net: 304 modules\n",
            "FLUX: Gradient checkpointing enabled. CPU offload: False\n",
            "prepare optimizer, data loader etc.\n",
            "use 8-bit AdamW optimizer | {'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01}\n",
            "override steps. steps for 100 epochs is / 指定エポックまでのステップ数: 2000\n",
            "enable full bf16 training.\n",
            "enable fp8 training for U-Net.\n",
            "enable fp8 training for Text Encoder.\n",
            "set U-Net weight dtype to torch.float8_e4m3fn\n",
            "prepare CLIP-L for fp8: set to torch.float8_e4m3fn, set embeddings to torch.bfloat16\n",
            "prepare T5XXL for fp8: set to torch.float8_e4m3fn, set embeddings to torch.bfloat16, add hooks\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 20\n",
            "  num validation images * repeats / 学習画像の数×繰り返し回数: 0\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 20\n",
            "  num epochs / epoch数: 100\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 2000\n",
            "steps:   0% 0/2000 [00:00<?, ?it/s]unet dtype: torch.float8_e4m3fn, device: cuda:0\n",
            "text_encoder [0] dtype: torch.float8_e4m3fn, device: cuda:0\n",
            "text_encoder [1] dtype: torch.float8_e4m3fn, device: cuda:0\n",
            "\n",
            "epoch 1/100\n",
            "\n",
            "epoch is incremented. current_epoch: 0, epoch: 1\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
            "steps:   0% 1/2000 [00:41<22:56:38, 41.32s/it, avr_loss=0.478]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSRKzk9ir6xT"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "import time\n",
        "print('Done')\n",
        "time.sleep(60)\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "--lr_scheduler=\"constant_with_warmup\" \\\n",
        "--network_args \"conv_dim=1\" \"conv_alpha=1\" \\\n",
        "--network_args \"loraplus_lr_ratio=16\" \\\n",
        "--optimizer_type=\"adamw8bit\" \\\n",
        "--optimizer_type=\"adafactor\" \\\n",
        "--optimizer_args \"relative_step=False\" \"scale_parameter=False\" \"warmup_init=False\" \"weight_decay=0.01\" \\\n",
        "--max_grad_norm=0 \\"
      ],
      "metadata": {
        "id": "0UnRJ0laQBoN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}